Abstract The development of neural networks for clini- cal artificial intelligence (AI) is reliant on in- terpretability, transparency, and performance. The need to delve into the black-box neural network and derive interpretable explanations of model output is paramount. A task of high clinical importance is predicting the likelihood of a patient being readmitted to hospital in the near future to enable efficient triage. With the increasing adoption of electronic health records (EHRs), there is great interest in applications of natural language processing (NLP) to clin- ical free-text contained within EHRs. In this work, we apply InfoCal (Sha et al., 2020), the current state-of-the-art model that produces ex- tractive rationales for its predictions, to the task of predicting hospital readmission using hospital discharge notes. We compare extrac- tive rationales produced by InfoCal to com- petitive transformer-based models pretrained on clinical text data and for which the atten- tion mechanism can be used for interpretation. We find each presented model with selected in- terpretability or feature importance methods yield varying results, with clinical language do- main expertise and pretraining critical to per- formance and subsequent interpretability. Keywords: Extractive rationales, NLP, adver- sarial training, hospital readmission, decision support Introduction The use of machine learning in clinical settings is be- coming widespread, and with the adoption of elec- tronic health records (EHRs) has produced big health data and been opened to modern machine learning approaches (Jiang et al., 2017; Vaci et al., 2020). Whilst ubiquitous, there is still a relative lack of up- take in the use of machine learning in live clinical settings, with neural networks often labelled black boxes. The transparency and explainability of neural networks is critical to trust and acceptance in clinical environments as useful tools. Research has sought to provide improved inter- pretability of NLP models using methods to derive extractive rationales for neural networks predictions by the model itself (Bastings et al., 2019; Lei et al., 2016; Sha et al., 2020). The aim of rationale produc- tion is to increase explainability of models by extract- ing the minimal crucial input required to make a class prediction. In NLP, the rationales are subsets of the input text which maintain predictive power. One of the ways rationales have been achieved is by creating a two-module network, i.e., a selector followed by a predictor, which are trained jointly (Lei et al., 2016). Given an input x, the selector picks a subset of the input features r(x) (the rationale) by specifying a dis- tribution over the possible rationales. The predictor acts as a standard classifier, taking as input r(x) and predicting a class yÃÂ to compare with the ground truth class y. Sha et al. (2020) proposed InfoCal, an improved type of selector-predictor model that uses an information calibration technique and an additional guider module trained jointly with the selector and predictor in an adversarial manner. InfoCal achieves the current state-of-the-art in rationale extraction on tasks such as sentiment analysis and legal judgment prediction, hence we are interested to see how it per- forms in the medical domain. In this work, we apply InfoCal to the task of predicting hospital readmission from EHRs (John- son et al., 2016). We compare InfoCal with clinical domain Bidirectional Encoder Transformer (BERT) models, ClinicalBERT (Huang et al., 2019) and Bio- ClinicalBERT (Alsentzer et al., 2019). Additionally we compare InfoCal exrractive rationales with impor- tance features in the BERT models via self-attention and layerwise relevance propagation (LRP). We find that the BERT models outperform InfoCal on the classification task, but has a relatively limited mech- anism for interpretability in the form of self-attention. InfoCal was able to produce extractive rationales which reach baseline performance on the classifica- tion task, and we argue the difficulty lies in the do- main expertise created by pretraining present in the BERT based models. Related Work With the advent of big data and machine learning, research is beginning to glean insights from the many types of EHRs data (Li et al., 2020; Huang et al., 2019;et al., 2020; Weng et al., 2017; Wang et al., 2018; Kuruvilla and Gunavathi, 2014; Barak-Corren et al., 2017; Johnson et al., 2016). Data within EHRs can be either structured (following a pre-defined data structure and type, such as ECG recordings, x-ray images, laboratory results, and de- mographics) or unstructured data (lacking formal rules, type, and bounds, such as the free-text clin- ical free-text contained within EHRs). The frequency and volume in which clinical text is recorded for the first time is critical to trust and acceptance in clinical environments. In this work, we apply InfoCal (Sha et al., 2020), the current state-of-the-art model that produces ex- tractive rationales for its predictions, to the task of predicting hospital readmission using hospital discharge notes. We compare extrac- tive rationales produced by InfoCal to com- petitive transformer-based models pretrained on clinical text data and for which the atten- tion mechanism can be used for interpretation. We find each presented model with selected in- terpretability or feature importance methods yield varying results, with clinical language do- main expertise and pretraining critical to per- formance and subsequent interpretability.